from random import random, Random, uniform, randint
from agentdefs import Environment

ENV_DIRTY = "DIRT"
ENV_CLEAN = "CLEAN"
ENV_WALL = "WALL"
ENV_GOLD = "GOLD"

ACTION_FORWARD = "FORWARD"
ACTION_SUCK = "SUCK"
ACTION_TURN_LEFT = "LEFT"
ACTION_TURN_RIGHT = "RIGHT"
ACTION_NOP = "NOP"
ACTION_SENSE_GOLD = "SENSEGOLD"
ACTION_MINE_GOLD = "MINEGOLD"
ACTION_UNLOAD_GOLD = "UNLOADGOLD"

class Percept:
    def __init__(self, attributes):
        self.attributes = attributes


class LIUVacuumEnvironment(Environment):

    """
    Create a vacuum environment with the given width, height, world-gen element biases and PRF seed
    """
    def __init__(self, env_x=5, env_y=5, dirt_bias=0.1, wall_bias=0.0, world_seed=None):
        super().__init__()
        self.env_x = env_x
        self.env_y = env_y
        self.dirt_bias = dirt_bias
        self.wall_bias = wall_bias
        #FIXME:  In the UI?
        self.gold_bias = 0.01
        self.world = None
        self.randomize_world(world_seed)

    """
    Add thing to environment
    """
    def add_thing(self, thing, location=None):
        # Facing x=1, y=0 (EAST)
        # Note, the facing determines the thing's "active" axis.
        # I.e. x=1 implies that the x-axis is "active" for this thing
        # This is useful for ACTION_FORWARD
        thing.facing = (1, 0)
        thing.performance = -1000.0
        super().add_thing(thing, location)

    """
    Generate a percept for an agent
    """
    def true_with_prob(self, p):
        return uniform(0, 1) <= p
    
    def isgold(self, p):
        return self.world[p[0]][p[1]] == ENV_GOLD
    
    def inbounds(self, pos):
        x, y = pos
        return x > 0 and x < self.env_x - 1 and y > 0 and y < self.env_y - 1
    
    def adjacent_at_distance(self, agent, n):
        r, c = agent.location
        if n == 0:
            l = [agent.location]
        elif n == 1:
            l = [(r+1, c), (r-1, c), (r, c+1), (r, c-1)]
        elif n == 2:
            l = [(r+2, c), (r-2, c), (r, c+2), (r, c-2),
                  (r+1, c+1), (r+1, c-1),
                  (r-1, c+1), (r-1, c-1)]
        else:
            raise(Exception(f"Bad arg {n} to adjacent"))
        return [p for p in l if self.inbounds(p)]
        
                
    def glitter_percept(self, agent):
        if any(self.isgold(p) for p in self.adjacent_at_distance(agent, 0)):
            p = self.true_with_prob(0.95)
        elif any(self.isgold(p) for p in self.adjacent_at_distance(agent, 1)):
            p = self.true_with_prob(0.75)
        elif any(self.isgold(p) for p in self.adjacent_at_distance(agent, 2)):
            p = self.true_with_prob(0.50)
        else:
            p = self.true_with_prob(0.01)
        if p:
            print(f"Glitter at {agent.location}")
        else:
            print(f"No Glitter at {agent.location}")
        return p
        
    def percept(self, agent):
        return Percept({"home": agent.location[0] == 1 and agent.location[1] == 1,
                        "dirt": self.world[agent.location[0]][agent.location[1]] == ENV_DIRTY,
                        "glitter": self.glitter_percept(agent) if agent.last_action == ACTION_SENSE_GOLD else None,
                        "bump": agent.bump})
  
    """
    Process actions generated by agents in environment
    """
    def execute_action(self, agent, action):

        agent.bump = False
    
        if action == ACTION_FORWARD:
            new_location = (agent.location[0] + agent.facing[0], agent.location[1] + agent.facing[1])
            agent.bump = self.world[new_location[0]][new_location[1]] == ENV_WALL
            agent.location = agent.location if agent.bump else new_location
        elif action == ACTION_SUCK:
            self.world[agent.location[0]][agent.location[1]] = ENV_CLEAN
        elif action == ACTION_TURN_LEFT:
            """
            NORTH -> WEST   |  ( 0, -1) -> (-1,  0)
            EAST  -> NORTH  |  ( 1,  0) -> ( 0, -1)
            SOUTH -> EAST   |  ( 0,  1) -> ( 1,  0)
            WEST  -> SOUTH  |  (-1,  0) -> ( 0,  1)
            """
            agent.facing = (agent.facing[1], -agent.facing[0] if agent.facing[0] != 0 else agent.facing[0])
        elif action == ACTION_TURN_RIGHT:
            agent.facing = (-agent.facing[1] if agent.facing[1] != 0 else agent.facing[1], agent.facing[0])        
        elif action == ACTION_SENSE_GOLD:
            pass
        elif action == ACTION_MINE_GOLD:   
            if self.world[agent.location[0]][agent.location[1]] == ENV_GOLD and agent.num_gold < 2:
                    agent.num_gold += 1
                    self.world[agent.location[0]][agent.location[1]] = ENV_CLEAN
        elif action == ACTION_UNLOAD_GOLD:
            if agent.location[0] == 1 and agent.location[1] == 1 and agent.num_gold > 0:
                agent.num_gold -= 1
                agent.add_gold_reward()
        elif action == ACTION_NOP:
            pass
        else:
            raise(Exception(f"Bad action {action}"))
                    
                

    """
    Start position for a given Thing in the environment
    """
    def default_location(self, thing):
        return 1, 1

    """
    Random-generate an environment for the vacuum with an optional seed
    """
    
    def wallify(self, randfunc):
        self.world =  [
                [
                ENV_WALL if
                    x == 0 or
                    x == self.env_x - 1 or
                    y == 0 or
                    y == self.env_y - 1 or
                    (randfunc() < self.wall_bias and not (x == 1 and y == 1))
                else ENV_CLEAN
                for y in range(self.env_y)
            ]
            for x in range(self.env_x)
        ]
        
    def dirtify(self, randfunc):
        for x in range(self.env_x-1):
            for y in range(self.env_y-1):
                if (self.world[x][y] != ENV_WALL):
                    if randfunc() < self.dirt_bias:
                        self.world[x][y] = ENV_DIRTY
                      
    def quadrant_for(self, r, c):
        m = int(self.env_x / 2)
        if r < m and c < m:
            return 0
        elif r < m and c >= m:
            return 1
        elif r >= m and c < m:
            return 2
        else:
            return 3
        
    def quadrant_positions(self, quadrant):
        m = int(self.env_x / 2)
        xrange = range(0, m) if quadrant < 2 else range(m, self.env_x)
        yrange = range(0,m) if quadrant == 0 or quadrant == 2 else range(m, self.env_y)
        return [(x, y) for x in xrange for y in yrange]
     
    def quadrant_sum(self, quadrant, state):
        return sum([1 if self.world_pos_state(p) == state else 0 for p in self.quadrant_positions(quadrant)])
    
    def world_pos_state(self, p):
        return self.world[p[0]][p[1]]
    
    def goldify(self, randfunc):
        quadrant_bias = [randint(1,3), randint(1,3), randint(1,3), randint(1,3)]
        for x in range(self.env_x-1):
            for y in range(self.env_y-1):
                if randfunc() * 1 / quadrant_bias[self.quadrant_for(x,y)] < self.gold_bias:
                    if self.world[x][y] == ENV_CLEAN:
                        self.world[x][y] = ENV_GOLD
                
    def randomize_world(self, seed=None):
        randfunc = random if seed is None else Random(seed).random
        self.wallify(randfunc)
        self.dirtify(randfunc)
        self.goldify(randfunc)
    
    # CAUTION!
    #   The position argument is possibly breaking since it's just 
    #   the default place where Things are placed (see defn of default_location)
    #   The heading argument is DEFINITELY breaking because "East" as a heading
    #   is defined in the agent world model.  But the internal representation of 
    #   East is something like (0,1) which is just too gross.
    
    def prep_agent(self, agent, recon_type):
        if recon_type == "Summary":
            recon = {'walls': self.env_positions(ENV_WALL), 
                     'gold': [self.quadrant_sum(q, ENV_GOLD) for q in [0,1,2,3]],
                     'dirt': [self.quadrant_sum(q, ENV_DIRTY) for q in [0,1,2,3]]
                     }
        elif recon_type == "Full":
            recon = {'width': self.env_x,
                     'height': self.env_y,
                     'position': (1,1),
                     'heading': 'East',
                     'walls': self.env_positions(ENV_WALL), 
                     'gold': self.env_positions(ENV_GOLD),
                     'dirt': self.env_positions(ENV_DIRTY)
                     }
        else:
            raise(Exception(f"Bad recon value {recon}"))
            
        agent.prep(recon)
    
    def env_positions(self, env):
        return [(r,c) for r in range(self.env_y) for c in range(self.env_x) if self.world[c][r] == env]
        
        
   
